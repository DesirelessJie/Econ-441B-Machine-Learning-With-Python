# -*- coding: utf-8 -*-
"""Econ-441B Week3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B0s-ERMknPEzXfrDWS6bJ0FvMUF5HNCi

# 1.) Import the Credit Card Fraud Data From CCLE
"""

import pandas as pd
from google.colab import drive
import matplotlib.pyplot as plt
import numpy as np
import warnings
warnings.filterwarnings("ignore")

drive.mount('/content/gdrive/', force_remount = True)

df = pd.read_csv("/content/gdrive/MyDrive/Econ441B/fraudTest.csv", header = 0)

df.head()

"""# 2.) Select four columns to use as features (one just be trans_date_trans)"""

df_select = df[["trans_date_trans_time", "category", "amt", "city_pop", "is_fraud"]]

df_select.columns

"""# 3.) Create a your own variable out of trans_date. Create dummies for factor vars"""

type(df_select["trans_date_trans_time"][0])

df_select["trans_date_trans_time"] = pd.to_datetime(df_select["trans_date_trans_time"])

dir(df_select["trans_date_trans_time"][0])

df_select["time_var"] = [i.second for i in df_select["trans_date_trans_time"]]

X = pd.get_dummies(df_select, ["category"]).drop(["trans_date_trans_time", "is_fraud"], axis = 1)
y = df["is_fraud"]

X.head()

"""# 5.) Train a Logistic regression."""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
nt = int(len(X)*0.8)
X_train = scaler.fit_transform(X.iloc[:nt])
X_test = scaler.fit_transform(X.iloc[nt:])
y_train = y.iloc[:nt]
y_test = y.iloc[nt:]

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(penalty='none')
log_reg = model.fit(X_train, y_train)

"""# 6.) The company you are working for wants to target at a False Positive rate of 5% what threshold should you use? (Use oversampled data)"""

# Get False Positive Rate, True Positive Rate and threshold
fpr, tpr, threshold = roc_curve(y_test, y_pred_proba)

# Iterate over different threshold values
for th in threshold:
    # Classify samples using the threshold
    y_pred = (y_pred_proba > th).astype(int)
    # Calculate the confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    # Calculate the false positive rate
    fpr = cm[0,1] / (cm[0,1] + cm[0,0])
    print("Threshold: {:.6f} FPR: {:.6f}".format(th, fpr))

from sklearn.metrics import roc_curve, auc, confusion_matrix
# Predict probabilities
y_pred_proba = log_reg.predict_proba(X_test)[:,1]

# Get False Positive Rate, True Positive Rate and threshold
fpr, tpr, threshold = roc_curve(y_test, y_pred_proba)

# Find the threshold at which fpr is closest to 5%
threshold = threshold[np.argmin(np.abs(fpr - 0.05))]

threshold

plt.figure(figsize=(30,8))
plt.bar(X.columns, log_reg.coef_[0])
plt.axhline(y = 0, color = "red")
plt.title("Logistic Regression Lasso output")
plt.xlabel("Beta")
plt.xticks(rotation=45)
plt.show()

"""# 7.) If the company makes .02*amt on True transactions and loses -amt on False (Use original data)"""

df_temp = df_select.iloc[nt:].copy()

y_scores = log_reg.decision_function(X_test)

# Use the threshold we get in the previous question
y_pred = (y_scores > threshold).astype(int)

df_temp["pred"] = y_pred

df_temp = df_temp[["pred", "is_fraud", "amt"]]

df_temp.head()

# Create an empty list to store the results
results = []

# Iterate over the rows of the dataframe
for i, row in df_temp.iterrows():
    # Get the predicted and true values
    predicted = row['pred']
    true = row['is_fraud']

    # Compare the predicted and true values
    if predicted == 1 and true == 1:
      results.append(0.02 * row["amt"])
    elif predicted == 0 and true == 1:
      results.append(-1.0 * row["amt"])
    elif predicted == 1 and true == 0:
      results.append(0.0)
    else:
      results.append(0.0)

# Add the results to the dataframe as a new column
df_temp['result'] = results

df_temp.result.sum()

"""# 8.) Using Logistic Regression Lasso to inform you. Would you use the selected features in a trusted prediction model?"""

# Create an instance of the LogisticRegression class with Lasso regularization
clf = LogisticRegression(penalty='l1', solver='saga', max_iter=10000)

# Fit the model to the training data
result = clf.fit(X_train, y_train)

# Make predictions on the test data
y_pred = clf.predict(X_test)

result.coef_[0]

plt.figure(figsize=(30,8))
plt.bar(X.columns, result.coef_[0])
plt.axhline(y = 0, color = "red")
plt.title("Logistic Regression Lasso output")
plt.xlabel("Beta")
plt.xticks(rotation=45)
plt.show()

print("Score:", result.score(X_test, y_test))

from sklearn.metrics import roc_curve, auc, confusion_matrix
# Predict probabilities
y_pred_proba = clf.predict_proba(X_test)[:,1]

# Get False Positive Rate, True Positive Rate and threshold
fpr, tpr, threshold = roc_curve(y_test, y_pred_proba)

# Find the threshold at which fpr is closest to 5%
threshold = threshold[np.argmin(np.abs(fpr - 0.05))]

threshold

df_temp = df_select.iloc[nt:].copy()
y_scores = log_reg.decision_function(X_test)
# Use the threshold we get in the previous question
y_pred = (y_scores > threshold).astype(int)
df_temp["pred"] = y_pred
df_temp = df_temp[["pred", "is_fraud", "amt"]]
df_temp.head()

# Create an empty list to store the results
results = []

# Iterate over the rows of the dataframe
for i, row in df_temp.iterrows():
    # Get the predicted and true values
    predicted = row['pred']
    true = row['is_fraud']

    # Compare the predicted and true values
    if predicted == 1 and true == 1:
      results.append(0.02 * row["amt"])
    elif predicted == 0 and true == 1:
      results.append(-1.0 * row["amt"])
    elif predicted == 1 and true == 0:
      results.append(0.0)
    else:
      results.append(0.0)

# Add the results to the dataframe as a new column
df_temp['result'] = results

df_temp[df_temp.result == 0.02]

df_temp.result.sum()

"""Nothing change, why with and without penalty there is no difference?"""
